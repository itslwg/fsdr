{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook for preparing the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from plotnine import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaults = pd.read_csv(\"./input/submission/defaults__submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaults.loc[:, 'report_id'] = defaults.loc[:, 'report_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_preparation import preprocess_lookups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing the lookups is expensive, and has been done before-hand. Uncomment to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess_lookups(nrows=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookups = pd.read_pickle(\"./input/submission/lookups_converted_fields__submission.df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lookups: 45995, Variables: 51\n",
      "Defaults: 4819, Variables: 3 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "Lookups: {lrows}, Variables: {lcols}\n",
    "Defaults: {drows}, Variables: {dcols} \n",
    "\"\"\".format(lrows = lookups.shape[0], lcols = lookups.shape[1],\n",
    "           drows = defaults.shape[0], dcols = defaults.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join with defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf = defaults.join(lookups, rsuffix=\"_r\").drop(columns=['report_id', 'report_id_r'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the loans that are missing lookup information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Joined dataframe, Rows: 4061, Cols: 52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "Joined dataframe, Rows: {rows}, Cols: {cols}\n",
    "\"\"\".format(rows=mdf.shape[0], cols=mdf.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unstack list columns so that we get one row per statement year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long = mdf.set_index(['loan_id', 'default_at_9']).apply(pd.Series.explode).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use only statements that covers 12 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long = df_long.loc[df_long['months_covered'] == 12].drop('months_covered', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup variables that are fractions and not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_preparation import fetch_fs_vars "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_vars = fetch_fs_vars()\n",
    "pct_vars =  []\n",
    "raw_vars = pd.Series(fs_vars)[~pd.Series(fs_vars).isin(pct_vars)].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset the vars plus the loan_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = df_long[['loan_id'] + raw_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_preparation import prepare_diffed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare three datasets:\n",
    "* One with the raw values statement values (already given by `df_long` if removing target),\n",
    "* One with the difference between the statement values, and \n",
    "* One with the sign of the difference between statement values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df_long[[\"default_at_9\", \"loan_id\"]].set_index(\"loan_id\")\n",
    "target.to_csv(\"./input/submission/target__submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_vals = df_long.drop(\"default_at_9\", axis=1)\n",
    "df_diff = prepare_diffed(df_raw, df_long, pct_vars, raw_vars, sign=False)\n",
    "df_diff_sign = prepare_diffed(df_raw, df_long, pct_vars, raw_vars, sign=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert all datasets to wide format, with previous statement values given as features. This computation is quite expensive, so the wide format data frames are prepared and then saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_preparation import long_to_wide\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wide_and_reset(df_base, features):\n",
    "    \"\"\"Util to make clean.\"\"\"\n",
    "    df_wide = df_base.groupby('loan_id').apply(long_to_wide, features=features)\n",
    "    df_wide.reset_index(level=0, drop=True, inplace=True)\n",
    "    return df_wide.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [04:25, 88.52s/it]\n"
     ]
    }
   ],
   "source": [
    "dfs = [df_raw_vals, df_diff, df_diff_sign]\n",
    "paths = [\"df_wide_raw_vals.df\", \"df_wide_diff.df\", \"df_wide_diff_sign.df\"]\n",
    "for df, path in tqdm(zip(dfs, paths)):\n",
    "    ## Pickle, instead of .to_csv to keep dtypes\n",
    "    X = wide_and_reset(df, features = raw_vars + pct_vars)\n",
    "    X.to_pickle(\"./input/submission/\" + path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
